{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delays original data source: https://www1.toronto.ca/wps/portal/contentonly?vgnextoid=fa6be8c5a612c510VgnVCM10000071d60f89RCRD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "delays = pd.read_csv('csv_originals/delays.csv', encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Day</th>\n",
       "      <th>Station</th>\n",
       "      <th>Code</th>\n",
       "      <th>Min Delay</th>\n",
       "      <th>Min Gap</th>\n",
       "      <th>Bound</th>\n",
       "      <th>Line</th>\n",
       "      <th>Vehicle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/1/2014</td>\n",
       "      <td>02:06</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>HIGH PARK STATION</td>\n",
       "      <td>SUDP</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>W</td>\n",
       "      <td>BD</td>\n",
       "      <td>5001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/1/2014</td>\n",
       "      <td>02:40</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>SHEPPARD STATION</td>\n",
       "      <td>MUNCA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YU</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/1/2014</td>\n",
       "      <td>03:10</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>LANSDOWNE STATION</td>\n",
       "      <td>SUDP</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>W</td>\n",
       "      <td>BD</td>\n",
       "      <td>5116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/1/2014</td>\n",
       "      <td>03:20</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>BLOOR STATION</td>\n",
       "      <td>MUSAN</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>S</td>\n",
       "      <td>YU</td>\n",
       "      <td>5386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/1/2014</td>\n",
       "      <td>03:29</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>DUFFERIN STATION</td>\n",
       "      <td>MUPAA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>E</td>\n",
       "      <td>BD</td>\n",
       "      <td>5174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date   Time        Day            Station   Code  Min Delay  Min Gap  \\\n",
       "0  1/1/2014  02:06  Wednesday  HIGH PARK STATION   SUDP          3        7   \n",
       "1  1/1/2014  02:40  Wednesday   SHEPPARD STATION  MUNCA          0        0   \n",
       "2  1/1/2014  03:10  Wednesday  LANSDOWNE STATION   SUDP          3        8   \n",
       "3  1/1/2014  03:20  Wednesday      BLOOR STATION  MUSAN          5       10   \n",
       "4  1/1/2014  03:29  Wednesday   DUFFERIN STATION  MUPAA          0        0   \n",
       "\n",
       "  Bound Line  Vehicle  \n",
       "0     W   BD     5001  \n",
       "1   NaN   YU        0  \n",
       "2     W   BD     5116  \n",
       "3     S   YU     5386  \n",
       "4     E   BD     5174  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delays.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date         False\n",
       "Time         False\n",
       "Day          False\n",
       "Station      False\n",
       "Code          True\n",
       "Min Delay    False\n",
       "Min Gap      False\n",
       "Bound         True\n",
       "Line          True\n",
       "Vehicle      False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delays.isnull().any()\n",
    "## Looks like Code, Bound and Line coutain NaNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dates = pd.to_datetime(delays['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2014, 2015, 2016, 2017]),\n",
       " array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12]),\n",
       " array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years = dates.dt.year\n",
    "months = dates.dt.month\n",
    "days = dates.dt.day\n",
    "years.unique(), months.unique(), days.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The years are between the expected 2014-2017 and the months/days look reasonable so no clean up on *Date*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 23, 0, 59)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hours = pd.to_datetime(delays['Time'], format='%H:%M').dt.hour\n",
    "minutes = pd.to_datetime(delays['Time'], format='%H:%M').dt.minute\n",
    "hours.min(), hours.max(), minutes.min(), minutes.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the hours are within 0 - 23 and the minutes are within 0-59 so no clean up needed for *Time*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday', 'Monday',\n",
       "       'Tuesday'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delays['Day'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Days look reasonable so no clean up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure the days from the day column match the day from the date?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Date</th>\n",
       "      <th>Date Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Day, Date, Date Day]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates_day = delays.copy()[['Day', 'Date']]\n",
    "dates_day['Date'] = pd.to_datetime(dates_day['Date'])\n",
    "dates_day['Date Day'] = dates_day['Date'].dt.weekday_name\n",
    "dates_day[dates_day['Date Day'] != dates_day['Day']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the *Day* column matches the expected date so no clean up here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41188             (APPROACHING)\n",
       "41018    0SSINGTON STATION (ENT\n",
       "70435       169 DANFORTH AVENUE\n",
       "39741    401 EMERGENCY EE (SHEP\n",
       "42551     APPROACHING DOWNSVIEW\n",
       "47634     APPROACHING HIGH PARK\n",
       "2531     APPROACHING KEELE STAT\n",
       "59133    APPROACHING KENNEDY BD\n",
       "39046      APPROACHING LAWRENCE\n",
       "66605    APPROACHING LAWRENCE S\n",
       "37369    APPROACHING LESLIE STA\n",
       "51425     APPROACHING OSSINGTON\n",
       "26048    APPROACHING VICTORIA P\n",
       "60229        APPROACHING WARDEN\n",
       "44476    APPROACHING WARDEN STA\n",
       "47937    APPROACHING WILSON STA\n",
       "20309         APPROACHING YONGE\n",
       "48403      APPROCHING DOWNSVIEW\n",
       "59520        APROACHING MCCOWAN\n",
       "27166        ASQUITH SUBSTATION\n",
       "22806     BATHURST (APPROACHING\n",
       "10064           BATHURST STAION\n",
       "158            BATHURST STATION\n",
       "17516    BATHURST STATION (APPR\n",
       "15497    BATHURST STATION (ENTE\n",
       "16813    BATHURST STATION (EXIT\n",
       "17325    BATHURST STATION (IN T\n",
       "18515    BATHURST STATION (LEAV\n",
       "13325    BATHURST STATION (WEST\n",
       "67072    BATHURST STATION - APP\n",
       "                  ...          \n",
       "58350    YORKDALE STATION ( APP\n",
       "141      YORKDALE STATION (APPR\n",
       "4369      YORKDALE STATION (ENT\n",
       "7833     YORKDALE STATION (ENTE\n",
       "651      YORKDALE STATION (EXIT\n",
       "572      YORKDALE STATION (LEAV\n",
       "14618    YORKDALE STATION (ON P\n",
       "8753     YORKDALE STATION (SOUT\n",
       "19865    YORKDALE STATION - APP\n",
       "55327    YORKDALE STATION - DEP\n",
       "8267     YORKDALE STATION APPRO\n",
       "64277    YORKDALE STATION BOOTH\n",
       "27454    YORKDALE STATION TO YO\n",
       "54219    YORKDALE STATION-BOOTH\n",
       "37295    YOUGE-UNIVERSITY AND B\n",
       "60007          YOUNG UNIVERSITY\n",
       "39667    YOUNG UNIVERSITY SUBWA\n",
       "15435    YOUNG/UNIVERSITY/SPADI\n",
       "16434    YOUNGE UNIVERSITY SPAD\n",
       "46806    YOUNGE/UNIVERISITY-BLO\n",
       "36970    YOUNGE/UNIVERSITY - LI\n",
       "43370    YOUNGE/UNIVERSITY-BLOO\n",
       "16643    YOUNGE/UNIVERSITY/SAPD\n",
       "37877     YPNGE/UNIVERSITY LINE\n",
       "50731                        YU\n",
       "996                         YUS\n",
       "1165              YUS & BD LINE\n",
       "2250                     YUS/BD\n",
       "13441    YUS/BD/SHEPPARD SUBWAY\n",
       "24074                YUS/BD/SRT\n",
       "Name: Station, Length: 2223, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delays['Station'].drop_duplicates().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'stations.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-5e74033c6ddd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Source https://www1.toronto.ca/wps/portal/contentonly?vgnextoid=c077c316f16e8410VgnVCM10000071d60f89RCRD&vgnextchannel=7807e03bb8d1e310VgnVCM10000071d60f89RCRD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mttc_stations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'stations.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mttc_stations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cindylopes/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cindylopes/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cindylopes/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cindylopes/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    964\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    967\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cindylopes/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1580\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1582\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__ (pandas/_libs/parsers.c:4209)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source (pandas/_libs/parsers.c:8873)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'stations.csv' does not exist"
     ]
    }
   ],
   "source": [
    "# Source https://www1.toronto.ca/wps/portal/contentonly?vgnextoid=c077c316f16e8410VgnVCM10000071d60f89RCRD&vgnextchannel=7807e03bb8d1e310VgnVCM10000071d60f89RCRD\n",
    "ttc_stations = pd.read_csv('stations.csv')\n",
    "ttc_stations.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The station in the above data all have their line in brackets but this will cause issues comparing to the delay data.\n",
    "\n",
    "Strip the station name from the bracket, the delay data has the exact line so we can use this to differentiate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttc_stations['Short Name'] = ttc_stations['Subway/RT Station'].dropna().str.split('(').str.get(0).str.upper().str.strip()\n",
    "\n",
    "# Fix up SHEPPARD and MAIN to match the delay data better\n",
    "ttc_stations[ttc_stations['Short Name'] == 'SHEPPARD-YONGE'] = 'SHEPPARD'\n",
    "ttc_stations[ttc_stations['Short Name'] == 'MAIN STREET'] = 'MAIN'\n",
    "\n",
    "# Drop any NaNs and grab just the uniques\n",
    "ttc_stations_names = ttc_stations['Short Name'].dropna().unique()\n",
    "\n",
    "'''\n",
    "Some stations have a 'West' version and ideally we want these first since we don't want to\n",
    "misclasify St. Clear West as St Clair so we reverse sort the names so the longer name is first\n",
    "'''\n",
    "ttc_stations_names = np.sort(ttc_stations_names)[::-1]\n",
    "\n",
    "ttc_stations_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the original stations and count how many there were"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delays['Station_original'] = delays['Station']\n",
    "stations = delays['Station']\n",
    "# 76801 Way too many stations!\n",
    "stations.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixing up some inconsistencies with the delays stations. The St are need to be normalized and some common typos fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_station(station):\n",
    "    if station.startswith('ST'):\n",
    "#         return station.replace('ST.', 'ST. ').replace('ST ', 'ST. ')\n",
    "        return station.replace('ST.', 'ST. ').replace('ST ', 'ST. ').replace('ST.  ', 'ST. ')\n",
    "    elif station == 'NORTH YORK CTR STATION' or station == 'NORTH YORK CENTER' or station == 'NORTH YORK CENTER STAT':\n",
    "        return 'NORTH YORK CENTRE'\n",
    "    elif '0SSINGTON' in station:\n",
    "        return station.replace('0SSINGTON', 'OSSINGTON')\n",
    "    elif 'BESSARIAN' in station or 'BESSARRION' in station:\n",
    "        return 'BESSARION'\n",
    "    elif 'BUTHURST' in station:\n",
    "        return 'BATHURST'\n",
    "    elif 'SCARB' in station or 'SCARBOROUGH' in station or 'SCAB' in station or 'SCAR' in station and 'RAPID' not in station:\n",
    "        return 'SCARBOROUGH CENTRE'\n",
    "    elif 'DOWNVIEW' in station:\n",
    "        return 'DOWNSVIEW'\n",
    "    else: \n",
    "        return station\n",
    "    \n",
    "# Store the newly fixed stations in it's own column  \n",
    "delays['Station_Fixed'] = delays['Station_original'].apply(fix_station)\n",
    "delays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a list of known stations and a cleaner list of stations lets take our best guess at the 'Normalized Station'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning** sometimes the above code is slow or gets stuck you can kill the kernal and restart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_station(original_station):\n",
    "    for station_name in ttc_stations_names:        \n",
    "        if station_name in original_station:\n",
    "            return station_name\n",
    "        \n",
    "    return np.NaN\n",
    "delays['Station'] = delays['Station_Fixed'].apply(estimate_station)\n",
    "delays.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next lets check out the stations that are still unknown -- also add a check here removing all the stations where the Line is null since those data points likely have issues with the stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delays\n",
    "unknown_station = delays[delays['Station'].isnull() & (delays['Line'].notnull())]\n",
    "len(unknown_station['Station_Fixed'].unique())\n",
    "# unknown_station['Station'].unique()\n",
    "print(len(unknown_station))\n",
    "unknown_station.groupby('Station_Fixed').size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like we weren't able to classify 342 of the original stations but from a quick glance some of of these aren't real station (like TRANISIT CONTORL, DANFORTH DIVISION )\n",
    "\n",
    "Interestingly some of there seem like entire lines or Systems (SYSTEM WIDE, SRT LINE ) which may be worth looking at individually than the stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick glance at the final stations\n",
    "delays.groupby('Station').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delays['Line'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Similar to station store the original lines\n",
    "delays['Line_ori'] = delays['Line']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the metadata that came with the data we know there are only 4 real lines so we can map these with their full name which will also convert the rest to null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expected_lines = {'BD': 'Bloor-Danforth', 'YU': 'Yonge-University', 'SHP' : 'Sheppard', 'SRT' : 'Scarborough RT'}\n",
    "delays['Line'] = delays['Line_ori'].map(expected_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intersection Stations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to rename the stations that are at the intersections (Bloor/Yonge/Sheppard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exchange_stations = delays[delays['Station'].isin(['BLOOR', 'SHEPPARD', 'YONGE', 'ST. GEORGE', 'KENNEDY', 'SPADINA'])]\n",
    "exchange_stations.groupby(['Station', 'Line']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fix_station(station, line, new_name):\n",
    "    delays.loc[(delays['Station'] == station) & (delays['Line'] == line), 'Station'] = new_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fix_station('BLOOR', 'Bloor-Danforth', 'BLOOR-YONGE - BD')\n",
    "fix_station('BLOOR', 'Yonge-University', 'BLOOR-YONGE - YU')\n",
    "fix_station('YONGE', 'Bloor-Danforth', 'BLOOR-YONGE - BD')\n",
    "fix_station('YONGE', 'Yonge-University', 'BLOOR-YONGE - YU')\n",
    "\n",
    "fix_station('SHEPPARD', 'Yonge-University', 'SHEPPARD - YU')\n",
    "fix_station('SHEPPARD', 'Sheppard', 'SHEPPARD - SHP')\n",
    "fix_station('YONGE', 'Sheppard', 'SHEPPARD - SHP')\n",
    "\n",
    "fix_station('SPADINA', 'Yonge-University', 'SPADINA - YU')\n",
    "fix_station('SPADINA', 'Bloor-Danforth', 'SPADINA - BD')\n",
    "\n",
    "fix_station('ST. GEORGE', 'Yonge-University', 'ST. GEORGE - YU')\n",
    "fix_station('ST. GEORGE', 'Bloor-Danforth', 'ST. GEORGE - BD')\n",
    "\n",
    "fix_station('KENNEDY', 'Scarborough RT', 'KENNEDY - SRT')\n",
    "fix_station('KENNEDY', 'Bloor-Danforth', 'KENNEDY - BD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exchange_stations = delays[delays['Station'].isin(['BLOOR', 'SHEPPARD', 'YONGE', 'ST. GEORGE', 'KENNEDY', 'SPADINA'])]\n",
    "exchange_stations.groupby(['Station', 'Line']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The meta data says that Bound should be a direction N/S/E/W so we can likely drop the B/R/Y which may have been typos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delays.groupby('Bound').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_directions = {'E': 'East', 'N': 'North', 'W':'West', 'S':'South'}\n",
    "delays['Bound'] = delays['Bound'].map(expected_directions)\n",
    "delays.groupby('Bound').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also know something about the lines -- Yonge/University line only goes North/South, Bloor Danforth/Sheppard/Scarboughout RT only does East/West so we can NaN any values that don't match that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delays_with_line = delays[delays['Line'].notnull()]\n",
    "num_non_null_bound = len(delays_with_line[delays_with_line['Bound'].notnull()])\n",
    "num_null_bound = len(delays_with_line[delays_with_line['Bound'].isnull()])\n",
    "total_delay = len(delays_with_line)\n",
    "\n",
    "print('Number of delays with non-null Bound: ', num_non_null_bound)\n",
    "print('Number of delays with null Bound', num_null_bound)\n",
    "print('Percentage of null ', (num_null_bound/total_delay))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix up the YU line\n",
    "non_null_yu = delays[(delays['Line'] == 'Yonge-University') & (delays['Bound'].notnull())]\n",
    "\n",
    "invalid_yu_mask = ~non_null_yu['Bound'].isin(['North','South'])\n",
    "invalid_yu = non_null_yu[invalid_yu_mask]\n",
    "num_invalid_yu = len(invalid_yu)\n",
    "print('Number of Invalid Bounds on the Yonge/Univerity line ', num_invalid_yu)\n",
    "print('Number of entries on the Yonge/Univerity line ', len(non_null_yu))\n",
    "print('Percent of Younge Line Bound being removed: ', num_invalid_yu/len(non_null_yu) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like 0.23% of the Yonge University Line Bounds were classified with the wrong Bond direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all the East/West to NaN\n",
    "yu_mask = (delays['Line'] == 'Yonge-University') & (delays['Bound'].notnull()) &(~delays['Bound'].isin(['North','South']))\n",
    "delays.loc[yu_mask, 'Bound'] = np.NaN\n",
    "delays[yu_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_null_other = delays[(delays['Line'] != 'Yonge-University') & (delays['Line'].notnull()) & (delays['Bound'].notnull())]\n",
    "\n",
    "invalid_other = non_null_other[~non_null_other['Bound'].isin(['East','West'])]\n",
    "num_invalid_other = len(invalid_other)\n",
    "print('Number of Invalid Bounds on the Other Line line ', num_invalid_other)\n",
    "print('Number of entries on the Other Lines ', len(non_null_other))\n",
    "print('Percent of Other Line Bound being removed: ', num_invalid_other/len(non_null_other) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all the North/South to NaN\n",
    "other_mask = (delays['Line'] != 'Yonge-University') & (delays['Line'].notnull()) & (delays['Bound'].notnull()) &(~delays['Bound'].isin(['East','West']))\n",
    "delays.loc[other_mask, 'Bound'] = np.NaN\n",
    "delays[other_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we will end up removing 6% of the other lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vehicle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empty vehicle numbers seem to be treated as 0 but NaN or None is likely more appropriate here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "delays['Vehicle'] = delays['Vehicle'].replace(0, np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vehicle_grouping = delays.groupby('Vehicle').size()\n",
    "# vehicle_grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vehicle_grouping.hist()\n",
    "vehicle_grouping.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We recieved the full code names from the data set so we can put the description in the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "codes = pd.read_csv('codes.csv')\n",
    "# Likely due to an encoding issue but the Code column is 'SUB RMENU CODE' so rename it to Code\n",
    "codes['Code'] = codes['SUB RMENU CODE']\n",
    "codes['Code Description'] = codes['CODE DESCRIPTION']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the codes into our delays dataframe we need to merge the codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delays = delays.merge(codes, how='left', on='Code')\n",
    "delays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let see if code codes didn't get translated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets see if any codes don't have description\n",
    "no_description = delays[delays['Code Description'].isnull()]\n",
    "print('Number of non decoded values: ', len(no_description))\n",
    "\n",
    "# Reverse sort by the number of entries of each of this code\n",
    "no_description.groupby('Code').size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like most of these are one off's with the exception of *MUNCA* which has 1561 values!\n",
    "One guess is this was meant to be MUNOA,No Operator Immediately Available - Not E.S.A. Related  or it could be missing from the code list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List out the codes with the most common one first\n",
    "delays.groupby('Code Description').size().sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Not really clean up I just was curcious how many of these were 'Passenger' related\n",
    "filled = delays['Code Description'].fillna('')\n",
    "pass_related = filled[filled.str.contains('Passenger')].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass_delays = delays[delays['Code Description'].isin(pass_related)]\n",
    "print(len(pass_delays))\n",
    "pass_delays.groupby('Code Description').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove some not really useful columns before exporting (CODE DESCRIPTION is a duplicate)\n",
    "delays = delays.drop(['Station_Fixed', 'SUB RMENU CODE', 'CODE DESCRIPTION'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delays.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "delays.to_csv('ttc_delays_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delays['Min Gap'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delays['Min Delay'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cleaned = pd.read_csv('ttc_delays_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
